{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import pydicom as dicom\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from pydicom import dcmread\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from keras_preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda,Dense,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "kernel_initializer =  'he_uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train_b = pd.read_csv(\"train_bounding_boxes.csv\")\n",
    "submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values('StudyInstanceUID',inplace=True,axis = 0)\n",
    "train_b.sort_values('StudyInstanceUID',inplace=True,axis = 0)\n",
    "train.reset_index(inplace=True,drop= True)\n",
    "train_b.reset_index(inplace=True,drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = sorted(os.listdir(r\"D:\\\\Projects\\\\Kaggle\\\\RSNA\\\\train_images\\\\\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b['startX']=0.0\n",
    "train_b['startY']=0.0\n",
    "train_b['endX']=0.0\n",
    "train_b['endY']=0.0\n",
    "for i in range(len(train_b)):\n",
    "    # calculate top,left for box\n",
    "    train_b['startX'][i] = train_b['x'][i] - (train_b['width'][i]/2)\n",
    "    train_b['startY'][i] = train_b['y'][i] + (train_b['height'][i]/2)\n",
    "    # calculate right,bottom for box\n",
    "    train_b['endX'][i] = train_b['x'][i] + (train_b['width'][i]/2)\n",
    "    train_b['endY'][i] = train_b['y'][i] - (train_b['height'][i]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(train)):\n",
    "#     dir  = r\"D:\\\\Projects\\\\Kaggle\\\\RSNA\\\\train_images\\\\\" + train['StudyInstanceUID'][i]\n",
    "#     for j in range(len(train_b)):\n",
    "#         if train['StudyInstanceUID'][i] == train_b['StudyInstanceUID'][j]:\n",
    "#             sec = str(train_b['slice_number'][j]) +\".dcm\"\n",
    "#             image_path= os.path.abspath(os.path.join(dir,sec))\n",
    "#             ds = dicom.dcmread(image_path)\n",
    "#             pixel_array_numpy = ds.pixel_array\n",
    "#             if pixel_array_numpy.shape != (512,512):\n",
    "#                 print(pixel_array_numpy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "targets = []\n",
    "filenames = []\n",
    "trainlabel = []\n",
    "for i in range(len(train)):\n",
    "    dir  = r\"D:\\\\Projects\\\\Kaggle\\\\RSNA\\\\train_images\\\\\" + train['StudyInstanceUID'][i]\n",
    "    for j in range(len(train_b)):\n",
    "        if train['StudyInstanceUID'][i] == train_b['StudyInstanceUID'][j]:\n",
    "            sec = str(train_b['slice_number'][j]) +\".dcm\"\n",
    "            image_path= os.path.abspath(os.path.join(dir,sec))\n",
    "            ds = dicom.dcmread(image_path)\n",
    "            pixel_array_numpy = ds.pixel_array\n",
    "            if pixel_array_numpy.shape != (512,512):\n",
    "                pixel_array_numpy =cv.resize(pixel_array_numpy, (512,512))\n",
    "            data.append(pixel_array_numpy/-255)\n",
    "            targets.append([train_b['startX'][j], train_b['startY'][j], train_b['endX'][j], train_b['endY'][j]])\n",
    "            filenames.append(train_b['StudyInstanceUID'][j])\n",
    "            cur_label = []\n",
    "            cur_label.append(train.loc[i,'C1'])\n",
    "            cur_label.append(train.loc[i,'C2'])\n",
    "            cur_label.append(train.loc[i,'C3'])\n",
    "            cur_label.append(train.loc[i,'C4'])\n",
    "            cur_label.append(train.loc[i,'C5'])\n",
    "            cur_label.append(train.loc[i,'C6'])\n",
    "            cur_label.append(train.loc[i,'C7'])\n",
    "            trainlabel += [cur_label]\n",
    "            print(trainlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = Input((512, 512 ,1))\n",
    "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    \n",
    "    #Expansive path \n",
    "    # u6 = Conv2DTranspose(128, (2, 2), strides=2, padding='same')(c5)\n",
    "    # u6 = concatenate([u6, c4])\n",
    "    # c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)\n",
    "    # c6 = Dropout(0.2)(c6)\n",
    "    # c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)\n",
    "     \n",
    "    # u7 = Conv2DTranspose(64, (2, 2), strides=2, padding='same')(c6)\n",
    "    # u7 = concatenate([u7, c3])\n",
    "    # c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)\n",
    "    # c7 = Dropout(0.2)(c7)\n",
    "    # c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)\n",
    "     \n",
    "    # u8 = Conv2DTranspose(32, (2, 2), strides=2, padding='same')(c7)\n",
    "    # u8 = concatenate([u8, c2])\n",
    "    # c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)\n",
    "    # c8 = Dropout(0.1)(c8)\n",
    "    # c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)\n",
    "     \n",
    "    # u9 = Conv2DTranspose(16, (2, 2), strides=2, padding='same')(c8)\n",
    "    # u9 = concatenate([u9, c1])\n",
    "    # c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)\n",
    "    # c9 = Dropout(0.1)(c9)\n",
    "    # c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)\n",
    "    f1 = Flatten()(p3)\n",
    "    d1 =  Dense(128, activation='relu')(f1)\n",
    "    d2 =  Dense(64, activation='relu')(d1)\n",
    "    d3 =  Dense(32, activation='relu')(d2)\n",
    "    outputs = Dense(4, activation='softmax')(d3)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    #compile model outside of this function to make it flexible. \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.compile(optimizer = \"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(x).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "split = train_test_split(x, y,trainlabel, test_size=0.10,\n",
    "\trandom_state=0)\n",
    "(trainImages, valImages) = split[:2]\n",
    "(trainTargets, valTargets) = split[2:4]\n",
    "\n",
    "(trainFilenames, valFilenames) = split[4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit(\n",
    "\ttrainImages, trainTargets,\n",
    "\tvalidation_data=0.1,\n",
    "\tbatch_size=64,\n",
    "\tepochs=3,\n",
    "\tverbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x[:3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "633bf2759fc0a7f4cda3481845fe7ea6530e49a0cd0358cdd14e096add1492c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
